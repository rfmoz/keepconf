#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# keepconf - Backup and track files from hosts keeping them inside a repository
# Copyright (C) 2015 - Ricardo F.

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import sys, optparse, os, glob, time, string, re, tempfile, logging
from configparser import ConfigParser
from subprocess import call
from distutils.util import strtobool
from distutils.dir_util import mkpath

__version__ = '2.1.00'
__config__ = '/etc/keepconf/'  # default configuration path
VERBOSE = 0

def get_arguments():
    """Get arguments from command line"""

    def print_version(*_):
        """Print version"""
        print('keepconf version ' + __version__)
        sys.exit(0)

    def enable_verbose(*_):
        """Enable verbose mode"""
        logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.DEBUG)
        global VERBOSE
        VERBOSE = 1

    parser = optparse.OptionParser()
    parser.add_option('-f', '--conf',
                      dest='config',
                      default=__config__,
                      action='store',
                      help='configuration file/folder path',
                      metavar="PATH")
    parser.add_option('-i', '--init',
                      dest='gitinit',
                      default=False,
                      action='store_true',
                      help='initialize git repostory')
    parser.add_option('-n', '--nocommit',
                      dest='commit',
                      default=True,
                      action='store_false',
                      help='avoid commit changes')
    parser.add_option('-c', '--commitonly',
                      dest='commitonly',
                      default=True,
                      action='store_false',
                      help='only commit changes')
    parser.add_option('-m', '--message',
                      dest='message',
                      default=False,
                      action='store',
                      help='commit message',
                      metavar="TEXT")
    parser.add_option('-s', '--silent',
                      dest='silent',
                      default=False,
                      action='store_true',
                      help='silent fetching output')
    parser.add_option('-x', '--xilent',
                      dest='xilent',
                      default=False,
                      action='store_true',
                      help='silent commit output')
    parser.add_option('-v', '--verbose',
                      action='callback',
                      callback=enable_verbose,
                      help='verbose output')
    parser.add_option('-V', '--version',
                      action='callback',
                      callback=print_version,
                      help='show version')
    options, _ = parser.parse_args()

    return options


def process_folder(str_folder, hosts, dest):
    """Execute all files located in a external folder"""
    # Test if is a directory
    if not os.path.isdir(str_folder):
        logging.info(str_folder +' not exists')
        return

    print('- Finding files in ' + str_folder)

    # Get all files inside the folder
    folder_files = sorted(glob.glob(str_folder + '*'))
    for b in folder_files:
        print('- Processing:', b)

        # Only execute executable files
        if not (os.path.isfile(b) and os.access(b, os.X_OK)):
            print('WARNING nothing done in non executable file ' + b)
        else:
            sys.stdout.flush()
            # File are called with:
            #  arg1: comma separated list of hosts
            #  arg2: "d_dest" variable
            call([b, str(",".join(hosts)), str(dest)])
            sys.stdout.flush()
    return


def yes_or_not(question):
    """Ask user for y/n"""
    sys.stdout.write('%s [y/n]\n' % question)
    while True:
        try:
            return strtobool(input().lower())
        except ValueError:
            sys.stdout.write('Please respond with \'y\' or \'n\'.\n')


# The following two functions are written by Chin Fang <fangchin@zettar.com>
# and are part of Ansible software located in github.com/ansible
# Are distributed under the terms of GNU General Public License
# (c) 2012, Zettar Inc.

def detect_range(line=None):
    """Detect is line have a range"""
    if 0 <= line.find("[") < line.find("-") < line.find("]"):
        return True
    else:
        return False


def expand_range(line=None):
    """Expand name range"""
    all_hosts = []
    if line:
        (head, nrange, tail) = line.replace('[', '|', 1).replace(']', '|', 1).split('|')
        bounds = nrange.split("-")
        if len(bounds) != 2 and len(bounds) != 3:
            print("WARNING: Range incorrectly specified")
        beg = bounds[0]
        end = bounds[1]
        if len(bounds) == 2:
            step = 1
        else:
            step = bounds[2]
        if not beg:
            beg = "0"
        if not end:
            print("WARNING: Range end value missing")
        if beg[0] == '0' and len(beg) > 1:
            rlen = len(beg)  # range length formatting hint
            if rlen != len(end):
                print("WARNING: Range format incorrectly specified")
            fill = lambda _: str(_).zfill(rlen)  # range sequence
        else:
            fill = str

        try:
            i_beg = string.ascii_letters.index(beg)
            i_end = string.ascii_letters.index(end)
            if i_beg > i_end:
                print("WARNING: Range format invalid")
            seq = string.ascii_letters[i_beg:i_end+1]
        except ValueError:  # not an alpha range
            seq = range(int(beg), int(end)+1, int(step))

        for rseq in seq:
            hname = ''.join((head, fill(rseq), tail))
            if detect_range(hname):
                all_hosts.extend(expand_range(hname))
            else:
                all_hosts.append(hname)
        return all_hosts


def sanitize(text_value):
    """Remove especial characters"""
    # Excluded characters
    excluded = "[\'\";|<>]"

    # Remove excluded characters and clean line
    resultd = re.sub(excluded, '', ((text_value.split('#', 1)[0].split(';', 1)[0]).strip()))
    if resultd:
        return resultd
    else:
        logging.info('excluded by sanitize: '+ text_value.strip())


def call_out(call_, silent_=None, cwd_='/tmp'):
    """Execute external program and redirect stdout and stderr to null if is needed"""
    if silent_:
        return call(call_, cwd=cwd_, stdout=open(os.devnull, 'w'), stderr=open(os.devnull, 'w'))
    else:
        return call(call_, cwd=cwd_)


def extract_walk(cfg_in_, walking=True):
    """Deconstruct path, extract elements"""
    # For store list to return
    paths_lst = []

    # For each element in the list of files/paths
    for g in cfg_in_:

        # For store path walk
        walk_lst = []

        # In some cases walking is not needed (for exclude files/paths)
        if walking:

            # Extract from path everything except the last pathname component and last '/'
            head, _ = os.path.split(g)

            # For each element separated by '/' add it to the list
            walk_path = ''
            for t in head.split('/'):
                walk_path += t + '/'
                walk_lst.append(walk_path)

        # For a comprensive behaviour than rsync do alone, add an asterisk
        # to the paths that ends in a slash or slash and asterisk
        if g.endswith('/') or g.endswith('/*'):
            logging.info('Adding * to: ' + str(g))
            g += '*'

        # Add origin path after its deconstructed route
        walk_lst.append(g)

        # Add processed path to the total amount
        paths_lst += walk_lst

    # Return sorted list
    return sorted(set(paths_lst))


def test_repo_dir(d_dest_, commit_):
    """Test the state of the destination repo dir"""
    if not os.path.isdir(d_dest_+'.git') and commit_:
        sys.exit('ERROR: '+str(d_dest_)+' not have a repository\nPlease, try to initialize it with \"keepconf -i\"')


def git_init(c):
    '''Initialize git repo. Create path and init or clone'''

    # Local repository
    if c['repo'] == 'local':
        if os.path.isdir(os.path.join(c['d_dest'], '.git')):
            print('WARNING: A .git folder exists inside '+ c['d_dest'] +' directory!')
            if not yes_or_not('Do you want to initialize an exiting repository?'):
                logging.info('Avoid initializating folder with .git directory')
                sys.exit(0)
        sys.stdout.flush()
        call(('git', 'init', c['d_dest']))
        sys.stdout.flush()

    # Remote repository
    elif c['repo']:
        if os.path.isdir(c['d_dest']):
            if os.listdir(c['d_dest']) != []:
                print('WARNING: Destination directory exists and is not empty!')
                print('Please, fix '+c['d_dest'])
                if not yes_or_not('Do you already did it, continue?'):
                    logging.info('Avoid clonning repository into destination folder: '+c['d_dest'])
                    sys.exit(0)
        else:
            logging.info('Creating directory'+ c['d_dest'])
            os.makedirs(c['d_dest'])
        print('Clonning repository...')
        sys.stdout.flush()
        call(('git', 'clone', c['repo'], c['d_dest']))
        sys.stdout.flush()

    else:
        sys.exit('ERROR initializating repository: ' + str(c['repo']))

    # Exit after initialize
    sys.exit(0)

def get_files_list(c, key1, key2):
    '''Get content of a list of files readed from config variable'''

    def parse_list(elements, values):
        '''Extract and clean lines from list'''
        for line in elements:
            try:
                lne = sanitize(line)
                if detect_range(lne):
                    logging.info('Range detected: '+ lne)
                    values = values + expand_range(lne)
                else:
                    values.append(lne)
            except:
                continue
        return values

    # For store list to return
    values = []

    # If key2 have something...
    if c[key2]:

        # Read lines and expand range if is the case
        values = parse_list(c[key2], values)

    # If key1 have something...
    if c[key1]:

        # For each file in the list
        for file_var in c[key1].replace(" ", "").split(',', 1):
            logging.info('Reading '+ key2 +' file: '+ file_var)

            # Test if if a file and open it
            if os.path.isfile(file_var):
                with open(file_var) as f:

                    # Read lines and expand range if is the case
                    values = parse_list(f, values)

                # Remove duplicate names and order
                values = sorted(set(values))
            else:
                print('  File not exists: '+ str(file_var))
    else:
        logging.info('Empty "'+ key1 +'"')
    logging.info(key1 +' list: ' + str(values))
    return values


def stats_and_csv(c, file_conf, hosts_ok, hosts_bad, start_time, time_fetched, time_committed):
    '''Print stats and write csv'''
    print('- ')

    if c['fetch']:
        print('- Hosts rsync\'ed: ' +'['+ str(len(hosts_ok)) +'] '+ ', '.join(hosts_ok))
        print('- Hosts not rsync\'ed: ' +'['+ str(len(hosts_bad)) +'] '+ ', '.join(hosts_bad))
        print('- Fetched in: %.2f seconds' % time_fetched)
    if c['commit'] and c['repo']:
        print('- Committed in: %.2f seconds' % time_committed)

    total_time = time.time() - start_time
    if c['fetch'] or c['commit']:
        print('- Completed in: %.2f seconds' % total_time)

    # Generate and write csv report file
    if c['d_monitor']:

        # Monitor file is destination path + name of configuration with replaced extension to .csv
        mon_file = str(c['d_monitor'] + os.path.splitext(os.path.basename(file_conf))[0] + '.csv')

        # Check if path exists, if not, do it
        if not os.path.isdir(c['d_monitor']):
            logging.info('Making destination csv folder: ' + str(c['d_monitor']))
            mkpath(c['d_monitor'])
        else:
            logging.info('Destination csv folder exists: ' + str(c['d_monitor']))

        # Clean monitor file
        with open(mon_file, "w"):  # clean monitor file
            pass

        # Create csv values
        if hosts_bad:
            hosts_bad_list = ","+ ','.join(['\"'+ x +'\"' for x in hosts_bad])
        else:
            hosts_bad_list = ''
        if hosts_ok:
            hosts_ok_list = "," +','.join(['\"'+ x +'\"' for x in hosts_ok])
        else:
            hosts_ok_list = ''

        # Write into file
        with open(mon_file, "a") as file_monitor:
            try:
                file_monitor.write('\"CFG-FILE\",\"' + os.path.basename(file_conf)+'\"\n')
            except:
                file_monitor.write('\"BadCfgFileName\"\n')
            try:
                file_monitor.write('\"OK\",\"' + str(len(hosts_ok)) + '\"' + hosts_ok_list + '\n')
            except:
                file_monitor.write('\"OK\",\"0\"\n')
            try:
                file_monitor.write('\"BAD\",\"' + str(len(hosts_bad)) + '\"' + hosts_bad_list + '\n')
            except:
                file_monitor.write('\"BAD\",\"0\"\n')
            try:
                file_monitor.write('\"FETCH-T\",\"%.2f' % time_fetched + '\"\n')
            except:
                file_monitor.write('\"FETCH-T\",\"0\"\n')
            try:
                file_monitor.write('\"COMMIT-T\",\"%.2f' % time_committed + '\"\n')
            except:
                file_monitor.write('\"COMMIT-T\",\"0\"\n')
            file_monitor.write('\"TOTAL-T\",\"%.2f' % total_time + '\"\n')

        print('- Monitor file: '+ str(mon_file))


def fetch_process(c, options):
    ''' Fetch files from hosts'''

    def rsync_host(c, options, f_walk, hosts_ok, hosts_bad):
        ''' Construct rsync call and fetch host'''
        # Define path name for store fetched files
        final_path = os.path.join(c['d_dest'], host)

        # Check if path exists, if not, do it
        if not os.path.isdir(final_path):
            logging.info('Making destination folder: ' + final_path)
            mkpath(final_path)
        else:
            logging.info('Destination folder exists: ' + final_path)

        print('- Fetching host: '+ host)

        # Construct ssh options:
        # If verbose is not used, quiet ssh mode
        if VERBOSE:
            ssh_loglevel = ''
        else:
            ssh_loglevel = ' -o LogLevel=quiet'

        # If rsync key is used, add it
        if c['rsync_key']:
            ssh_key = ' -i '+str(c['rsync_key'])
        else:
            ssh_key = ''

        # ssh options '-oStrictHostKeyChecking=no' and '-oUserKnownHostsFile=/dev/null' are for
        # for avoid annoying errors in rsync when hosts are new.
        # If you need security, please comment the following line and uncomment the next.
        ssh_opt = 'ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -p '+ c['rsync_port'] + ssh_loglevel + ssh_key
        #ssh_opt = 'ssh -p '+ c['rsync_port'] + ssh_loglevel + ssh_key

        # Create rsync call. For modify it, the place is the following line:
        rsync_call = ('rsync', '-e', ssh_opt, '-'+c['rsync_opt'], '--progress', '--delete-excluded',
                      '--timeout='+c['rsync_timeout'], '--ignore-errors', '--max-size='+c['max_size'],
                      '--include-from=' + f_walk.name, '--prune-empty-dirs', c['rsync_user']+'@'+host+':/', final_path)
        logging.info(' '.join(map(str, rsync_call)))

        # Execute rsync and construct list with ok and bad hosts
        sys.stdout.flush()
        if (call_out(rsync_call, options.silent, c['d_dest'])) == 0:
            hosts_ok.append(host)
        else:
            hosts_bad.append(host)
        sys.stdout.flush()
        
        return hosts_ok, hosts_bad

    # Define list for store ok and bad fetched hosts
    hosts_ok, hosts_bad = [], []

    test_repo_dir(c['d_dest'], c['commit'])
    print('- Fetching start')

    # Get list of files with hostnames
    c['hosts'] = get_files_list(c, 'list_hosts', 'hosts')

    # Almost one host for process
    if not c['hosts']:
        print('  Any host for fetch. Skipping')
        return hosts_ok, hosts_bad

    # Get list of files with filelist
    c['files'] = get_files_list(c, 'list_files', 'files')

    # Execute pre-get.d
    if c['pre_get']:
        process_folder(c['pre_get'], c['hosts'], c['d_dest'])

    # Construct lists for each includes / excludes / force includes files. Clean duplicates and order
    for fpath in c['files']:
        if fpath.startswith('!'):
            logging.info('Exclude: '+ fpath[1:].rstrip())
            c['cfg_ex'].append(fpath[1:])
        elif fpath.startswith('&'):
            logging.info('Force Incl: '+ fpath[1:].rstrip())
            c['cfg_frz'].append(fpath[1:])
        else:
            logging.info('Include: '+ fpath.rstrip())
            c['cfg_in'].append(fpath)
    for val in ('cfg_in', 'cfg_ex', 'cfg_frz'):
        c[val] = sorted(set(c[val]))

    # Create temporary file for store the list of files and pass later to rsync
    _, f_tmp_walk = tempfile.mkstemp()
    f_walk = open(f_tmp_walk, 'w')

    # Write into temp file each list before extract the path to the file/folder.
    # This order of list (force>exclude>include) is a requirement for the file.
    if c['cfg_frz']:
        paths_lst_frz = extract_walk(c['cfg_frz'])
        logging.info('Force paths: '+str(c['cfg_frz'])+'->'+str(paths_lst_frz))
        for e in paths_lst_frz:
            f_walk.write('+ ' + e + '\n')

    if c['cfg_ex']:
        paths_lst_ex = extract_walk(c['cfg_ex'], False)
        logging.info('Exclude paths: '+str(c['cfg_ex'])+'->'+str(paths_lst_ex))
        for e in paths_lst_ex:
            f_walk.write('- ' + e + '\n')

    if c['cfg_in']:
        paths_lst_in = extract_walk(c['cfg_in'])
        logging.info('Include paths: '+str(c['cfg_in'])+'->'+str(paths_lst_in))
        for e in paths_lst_in:
            f_walk.write('+ ' + e + '\n')

    # The temp file must have always the following last line
    f_walk.write('- *\n')

    # Close temporary file with the list of files used by rsync
    f_walk.close()

    # For each hostname in the list, rsync it.
    for host in c['hosts']:
        rsync_host(c, options, f_walk, hosts_ok, hosts_bad)

    # Don't delete file if verbose mode is enabled (for easy debug)
    if VERBOSE:
        logging.info('WARNING temporary files not deleted in verbose mode')
    else:
        os.remove(f_tmp_walk)

    # Execute post-get.d
    if c['post_get']:
        process_folder(c['post_get'], c['hosts'], c['d_dest'])

    print('- Fetching done')
    return hosts_ok, hosts_bad


def fetch_commit(c, options, hosts_ok, hosts_bad):
    ''' Commit files fetched'''

    test_repo_dir(c['d_dest'], c['commit'])
    print('- Committing start')

    # Execute pre-commit.d
    if c['pre_commit']:
        process_folder(c['pre_commit'], c['hosts'], c['d_dest'])

    # Parse message option. Use default or custom.
    if options.message:
        message = 'Keepconf: ' + options.message
    else:
        message = 'Keepconf commit at '+time.strftime('%H:%M:%S - %A/%B/%Y')
        if hosts_ok or hosts_bad:
            message += '\nHosts ok: '+'['+ str(len(hosts_ok))+'] ' + ', '.join(hosts_ok)
            message += '\nHosts bad: '+'['+ str(len(hosts_bad))+'] ' + ', '.join(hosts_bad)

    # Commit files into local or remote repository
    sys.stdout.flush()
    if c['repo'] == 'local':
        print('- Committing into local repository')
        call_out(('git', 'add', c['d_dest']+'*'), options.xilent, c['d_dest'])
        call_out(('git', 'commit', '-am', message), options.xilent, c['d_dest'])
    else:
        # print('- Updating remote repository')
        # call_out(('git', 'pull'), options.xilent, cwd=c['d_dest'])
        print('- Committing into remote repository')
        call_out(('git', 'add', '--all'), options.xilent, c['d_dest'])
        call_out(('git', 'commit', '-am', message), options.xilent, c['d_dest'])
        call_out(('git', 'push'), options.xilent, c['d_dest'])
    sys.stdout.flush()

    # Execute post-commit.d
    if c['post_commit']:
        process_folder(c['post_commit'], c['hosts'], c['d_dest'])

    print('- Committing done')

def assign_variable(c, parser, section, key, normpath=False):
    '''Assign variables from config file'''
    try:
        # Normalize and/or sanitize variables
        if normpath:
            value = os.path.normpath(sanitize(parser.get(section, key)))+os.sep
        else:
            value = sanitize(parser.get(section, key))
        if value.lower() in ('false', '0', 'not'):
            value = False
    except:
        # In case of problems, assign default value
        value = c[key]

    logging.info('['+section +'] '+ key +': '+ str(value))
    return value


def main():
    """main entry point, manage behaviour based on configuration"""

    # Default values
    c = {
        'd_dest': False,
        'd_monitor': False,
        'list_hosts': False,
        'list_files': False,
        'fetch': True,
        'pre_get': False,
        'post_get': False,
        'max_size': '25M',
        'rsync_user': 'backup',
        'rsync_key': None,
        'rsync_port': '22',
        'rsync_timeout': '5',
        'rsync_opt': 'arHvzL',
        'commit': True,
        'pre_commit': False,
        'post_commit': False,
        'repo': 'local'}

    # Get arguments from command line
    options = get_arguments()

    logging.info('Parsing configuration path: '+ options.config)

    # Test if config path is a file or a folder, in that case, retrieve all .cfg files
    if os.path.isfile(str(options.config)):
        logging.info('Config path is a file')
        conf_list = (options.config,)
    else:
        logging.info('Config path is a folder')
        conf_list = sorted(glob.glob(options.config + '*.cfg'))
    logging.info('Files for process: ' + str(conf_list))

    # Almost one configuration file
    if len(conf_list) == 0:
        logging.error('Any valid configuration files for use')

    # Process each configuration file
    for index, file_conf in enumerate(conf_list):

        # Start timer for the whole process
        start_time = time.time()
        time_fetched = ''
        time_committed = ''

        # Set empty values for hosts
        hosts_ok = ''
        hosts_bad = ''

        # For more than one file, add separate banner
        if index > 0:
            print('\n-------------------------\n')

        print('- Processing: '+ str(file_conf))

        # Parse options in config file
        parser = ConfigParser(allow_no_value=True)
        parser.read(file_conf)

        # Assign variables from config file to main dictionary
        c['d_dest'] = assign_variable(c, parser, 'main', 'd_dest')
        c['list_hosts'] = assign_variable(c, parser, 'hosts', 'list_hosts')
        c['hosts'] = []  # For fulfill later with hostname list
        for line, _ in (parser.items('hosts')):
            if not line == 'list_hosts':
                line = (sanitize(line))
                c['hosts'].append(line)
        c['list_files'] = assign_variable(c, parser, 'files', 'list_files')
        c['files'] = []  # For fulfill later with files list
        for line, _ in (parser.items('files')):
            if not line == 'list_files':
                line = (sanitize(line))
                c['files'].append(line)
        c['d_monitor'] = assign_variable(c, parser, 'main', 'd_monitor')
        if options.commitonly:
            c['fetch'] = assign_variable(c, parser, 'sync', 'fetch')
        else:
            c['fetch'] = False
        c['pre_get'] = assign_variable(c, parser, 'sync', 'pre_get', normpath=True)
        c['post_get'] = assign_variable(c, parser, 'sync', 'post_get', normpath=True)
        c['max_size'] = assign_variable(c, parser, 'sync', 'max_size')
        c['rsync_user'] = assign_variable(c, parser, 'sync', 'rsync_user')
        c['rsync_key'] = assign_variable(c, parser, 'sync', 'rsync_key')
        c['rsync_port'] = assign_variable(c, parser, 'sync', 'rsync_port')
        c['rsync_opt'] = assign_variable(c, parser, 'sync', 'rsync_opt')
        if options.commit:
            c['commit'] = assign_variable(c, parser, 'vcs', 'commit')
        else:
            c['commit'] = False
        c['pre_commit'] = assign_variable(c, parser, 'vcs', 'pre_commit', normpath=True)
        c['post_commit'] = assign_variable(c, parser, 'vcs', 'post_commit', normpath=True)
        c['repo'] = assign_variable(c, parser, 'vcs', 'repo')
        c['cfg_ex'] = []  # For fulfill later with excluded files list
        c['cfg_frz'] = []  # For fulfill later with force include files list
        c['cfg_in'] = []  # For fulfill later with include files list

        # Check "d_dest" directory requirements
        if (not options.gitinit and c['commit']) and not os.path.isdir(str(c['d_dest'])):
            sys.exit('ERROR: \"'+ str(c['d_dest']) +'\" is not a valid \"d_dest\" directory or is not initialized.\nPlease, try to execute \"keepconf -i -f '+ file_conf +'\"')

        # Run init option
        if options.gitinit:
            git_init(c)

        # Run fetch (no commit) option
        if c['fetch']:

            # Start timer for fetch
            fetch_time = time.time()

            # Fetching process. Report ok and bad host list
            hosts_ok, hosts_bad = fetch_process(c, options)

            # Register total fetch time
            time_fetched = time.time() - fetch_time

        else:
            logging.info('Avoid fetching files')

        # Run commit option
        if c['commit'] and c['repo']:

            # Start timer for commit
            commit_time = time.time()

            # Commit process
            fetch_commit(c, options, hosts_ok, hosts_bad)

            # Register total commit time
            time_committed = time.time() - commit_time

        else:
            logging.info('Avoid committing changes')

        # Run stats
        if c['fetch'] or (c['commit'] and c['repo']):
            stats_and_csv(c, file_conf, hosts_ok, hosts_bad, start_time, time_fetched, time_committed)

if __name__ == "__main__":
    main()
